\chapter{Introduction}
\label{chap:introduction}

Developing the metatheory of formal systems such as logics and programming
languages is central to establishing trust in those systems.
Such trust is essential since quite sophisticated programming languages, having
a multitude of features, are used to create the vast bodies of software that
surround us in the modern world.
However, as a system of study becomes more complex, so does its metatheory.
Developing a proof on paper, although an excellent strategy for gaining an
intuition for the proof's correctness, does not provide a bulletproof assurance
of its correctness.
Instead, one can seek a higher standard of correctness by \emph{mechanizing} the
metatheory.
That is, one can verify a proof using software called a proof assistant.

Alas, using a proof assistant is not as simple as one might hope.
One must first \emph{encode} the system of study in the assistant.
Next, one must formulate the statements of the theorems and their proofs in a
way that the assistant can automatically verify.
How one goes about resolving both of these concerns depends greatly on the
chosen proof assistant.

Proof assistants come in many shapes and flavours, as building such an
assistant requires that one make some extremely impactful choices.
What underlying theory will it use?
How will a user interact with it?
What sorts of proofs is it specialized for, if any?
In assistants specialized for mechanizing metatheory, a key question is:
how to represent variables, (simultaneous) substitutions, assumptions,
derivations that depend on assumptions, and the proof state?
These decisions greatly influence how easy (or how cumbersome) it might be to
encode various formal systems and to reason about them.

% That is, these assistants exploit a beautiful phenomenon that links proofs with
% programs, called the Curry-Howard correspondence.
%
% This correspondence first observes that the connectives from logic, such as
% implications and quantifiers, can be reinterpreted as type formers in an
% appropriate functional programming language.
% For example, a logical proposition ``$A$ implies $B$'', written formally as
% $A \implies B$, can be reinterpreted as the type $A \to B$, i.e. the type of
% functions from type $A$ to type $B$.
% This is called the \emph{propositions-as-types} principle.
% Second, the correspondence observes that the \emph{proof}
% of a proposition $A$ can be reinterpreted as a \emph{program} belonging to the
% type $A$.
% This aspect of the correspondence is called the \emph{proofs-as-programs}
% principle.
% Typechecking a program then corresponds to checking that the proof that it
% represents indeed does prove the proposition that one claims it to prove.

% This correspondence explains precisely why a proof assistant can take the form
% of a programming language at all:
% programming and proving are one and the same.
% However, a property one cares greatly about in a logic is its
% \emph{consistency}.
% That is, it ought to be impossible to derive a falsehood.

\Beluga~\cite{Pientka:IJCAR10,Pientka:CADE15} is a proof assistant which
provides sophisticated infrastructure for implementing formal systems based on
the logical framework LF~\cite{Harper93jacm}.
This allows programmers to uniformly specify syntax, inference rules, and
derivation trees using higher-order abstract syntax (HOAS) and relieves users
from having to build custom support for managing variable binding,
renaming, and substitution.

Following the Curry-Howard correspondence, \Beluga{} users develop inductive
metatheoretic proofs about formal systems by writing a total recursive
dependently-typed program by pattern matching on derivation trees.
Given that the proof is represented as a program, proof checking amounts to
typechecking the program.
\Beluga{} hence follows in the foot steps of proof checkers such as Automath
\cite{Nederpelt:94}, Agda \cite{Norell:phd07}, and specifically Twelf
\cite{Pfenning99cade}.

While writing a proof as a dependently typed program is a beautiful idea, it
can be quite challenging and cumbersome.\todo{why?}
This limits the widespread use of dependently-typed programming languages for
mechanizing proofs in general.
Hence, many proof assistants in this domain provide some form
of interactivity: for example, Agda \cite{Norell:phd07} supports leaving holes
(question marks) and writing partial programs which can later be refined using a
fixed limited set of interactions.
However a clear specification and theoretical foundation of how these
interactions transform programs is largely missing.
In \Coq{} \cite{bertot/casteran:2004} users interactively develop a proof using
\emph{tactics}.
Behind the scenes, a sequence of tactic applications is elaborated into a
dependently-typed program.
Ideally, applying successfully a tactic to a proof state should only result in a
new valid, consistent proof state, but this isn't always the case: user-defined
tactics for \Coq{} constructed in the Ltac language \cite{Delahaye:LPAR00} are
mostly unconstrained; it is \Coq's typechecker that verifies post hoc that the
program generated by the tactics is valid.
A common additional caveat of tactic languages is that often, the resulting
proof script is brittle and unreadable.

In this thesis, I present the design and implementation of \Harpoon, an
interactive proof environment built on top of \Beluga, where programmers develop
proofs using a fixed set of tactics.
The user invokes an action on a subgoal in order to eliminate it, possibly
introducing new subgoals in doing so.
Our fixed set of tactics is largely inspired by similar systems such as
Abella \cite{Gacek:IJCAR08} and Coq, supporting introduction of assumptions,
case-analysis, and inductive reasoning, as well as both forward and backward
reasoning styles.
As \Harpoon{} is built on top of \Beluga{}, its tactics can also refer to a
Beluga{} programs to provide an explicit proof witness to justify a proof step.
The ability to seamlessly mix programming with command-driven interactive
theorem proving is particularly useful when appealing to a lemma and switching
between proving and programming.
Finally, successful tactic application is guaranteed to transform a valid proof
state into another valid proof state.
%
\Harpoon's command-driven front-end generates automatically as a result a proof
script that reflects the subgoal structure.
I think of a proof script as an intermediate proof representation language to
facilitate translation to other formats, such as into (executable) \Beluga{}
programs as shown in this thesis or perhaps eventually into a human-readable
proof format. My specific contributions are the following:

\begin{figure}[t]
  \centering
  \input{figs/harpoon-diagram}
  \caption{\Harpoon{} Design Overview}
  \label{fig:harpoon}
\end{figure}

\begin{itemize}
\item
  I present the design and implementation of \Harpoon, an
  interactive command-driven front-end of \Beluga{} for mechanizing
  meta-theoretic proofs.
  Starting from a user-specified theory (including both its syntax and its
  judgments), users interactively develop metatheoretic proofs using tactics.
  In tutorial style, I use \Harpoon{} to interactively develop a proof in
  Chap.~\ref{chap:example} by way of giving a whirlwind tour of the main
  supported tactics in \Harpoon.

\item
  In Chap.~\ref{chap:theory}, I describe a logical foundation for interactive
  proof development. To that end, I explain first in Sec.~\ref{sec:harpoon} a
  proof script language that reflects the proof structure laid out by the
  user. This language clearly separates forwards and backwards reasoning.
  Then, I explain formally the interactive tactics and their connection to proof
  scripts. I prove soundness of interactive proof construction, and give a
  translation from proof scripts into \Beluga{} programs, showing that this
  translation is type-preserving.
  This justifies that proof scripts indeed represent proofs and form a valid way
  to develop metatheory, and also allows proof scripts to not only be
  typechecked, but also executed as programs.
  Fig.~\ref{fig:harpoon} summarizes the connection among tactics, proof
  scripts, and \Beluga{} programs.

\item
  I characterize and reason about incomplete programs using
  \emph{contextual types}.
  A variable of such a type, which I call a \emph{subgoal variable}, represents a
  hole in the proof, i.e. a statement to prove together with a set of available
  assumptions.
  My formalism of incomplete proofs is such that holes are independent of each
  other and may be solved in any order.
  I show that incremental proof development amounts of successively applying
  contextual substitutions to eliminate a subgoal variable, while possibly
  introducing new ones.

\item
  \Harpoon{} is implemented as part of \Beluga{} and is documented together with
  \Beluga{} at \url{https://beluga-lang.readthedocs.io/}.
  We have used \Harpoon{} for a range of representive examples from the
  \Beluga{} library, in particular type safety proofs for
  MiniML, normalization proofs for the simply-typed lambda calculus
  \cite{Cave:MSCS18},
  % a higher-order solution to POPLMark \cite{Pientka:TPHOLs07},
  benchmarks for reasoning about binders
  \cite{Felty:MSCS17,Felty:orbi-survey},
  and the recent POPLMark Reloaded challenge \cite{POPLMarkReloaded:19}.
  These examples cover a wide range of aspects that arise in the
  proof development such as complex reasoning with and about contexts,
  context schemas, substitutions, and variables.
\end{itemize}

% While we design an interactive proof development engine for \Beluga, we believe there are some general lessons one can draw from our design:

% \paragraph{Remark [possibly to be moved elsewhere or to be removed -bp]} One might ask, why not generate directly from the interactive commands a dependently-typed program. There are several reasons why we chose to introduce a proof script language as an intermediate language: 1) When proving a property, we focus on the logical statement (= type) and the logical rules of inference. While there is an isomorphism between proofs and programs, we still think that it is often easier to think of the proof rather than the program. As our language allows us to embed programs into proof scripts, both can live together and the user can mix them and ultimately choose what is most convenient. 2) When writing a dependently typed program, one needs to understand the proof/program state for holes (open goals). Keeping track of types in the programmers head works for simply typed programs, but for dependently typed programs this becomes increasingly challenging. Hence, systems such as \Agda{} (or \Beluga) display the proof state for a given open subgoal (hole). This gives some indication of how important thinking about types rather than programs becomes.   3) Refining dependently typed programs is challenging in practice -- this is mostly due to the fact that a programer omits implicit arguments in the source program to make dependently typed programs more readable and compact; the program is then elaborated into an internal abstract syntax tree where all the omitted information has been inferred. When refining a partial dependently typed program, we typically refine the internal abstract syntax tree -- however to return the result of the program refinement back to the user, we need to again erase implicit arguments.

% A proof script which is structured representation of the proof attempt allows programmers to seamlessly switch between programming and proving; as proof scripts are more verbose, we can state clearly what it means to refine a proof script; as the proof script is generated automatically and not written by the programmer, it does not matter that it is verbose; verbosity in fact helps to generate programs from proof scripts; we also see proof scripts as a good intermediate representation to generate human-readable proofs.

%%% Local Variables:

%%% TeX-master: "../main.tex"
%%% End:

\chapter{Background}
\label{chap:background}

Before presenting my work, I review in this chapter some of the foundations upon
which it rests.
First, I broadly discuss tactic languages in
Sec.~\ref{sec:tactics-tacticals} before moving on to languages used for
defining tactics in Sec.~\ref{sec:defining-tactics}.
Next, since Harpoon can be viewed also as a form of structured editor for
proofs, I survey the literature on structured editing in
Sec.~\ref{sec:structured-editing}.
Finally, I discuss the Beluga project at large since Harpoon builds directly on
Beluga.

\section{Tactics and tacticals}
\label{sec:tactics-tacticals}

\subsection{Origins: the LCF system}

Now a common word in today's proof assistant jargon, the notion of \emph{tactic}
as we know it was introduced by Robin Milner nearly 40 years ago
as part of the Logic for Computable Functions (LCF) system
\cite{milner-tactics, lcf}.
This system is specialized for reasoning in a logic called \textsc{pplambda}, a
polymorphic predicate lambda-calculus, based on Dana Scott's Logic \emph{of}
Computable Functions \cite{scott-lcf}.
Although the way we use tactics has evolved somewhat since then, the core idea
remains remarkably the same: a tactic is a function applied to a goal to
eliminate it, producing zero or more new goals.
This view of tactics is natural if one understands an inference rule as a
function from theorems to theorems: a primitive tactic is merely the inverse of
an inference rule, mapping the conclusion of that rule to its necessary
premises.
As not every tactic is applicable to every goal, Milner defines a tactic
specifically as a partial function.
A tactic produces also as output a function that Milner calls a
\emph{validation}.
This function accepts a list of theorems -- the eventual solutions to the new
goals generated by the tactic -- and produces a new theorem.
This is due to the crucially backwards orientation of the tactics-based
approach: tactics act on a \emph{goal} (a desired end state), so validations
are composed together once the proof is complete to form a forwards proof.

\newcommand{\theorem}{\mathtt{theorem}}
For example, a tactic representing the rule for $\land$-introduction
applied to a goal of the form $A \land B$ generates two subgoals, $A$ and
$B$.
The validation generated by the tactic expects a list of two theorems, one for
$A$ and one for $B$, and constructs the theorem $A \land B$ using the function
representing the $\land$-introduction rule,
of type $\theorem \to \theorem \to \theorem$.

The core tactics in LCF are simply the inference rules of \textsc{pplambda}, but
having only these would be quite limiting.
Constructing even small proofs would be a hugely laborious task in that case.
To make the tactic-based approach to proving more practical, Milner
introduces tactic combinators called \emph{tacticals}.
These can take advantage of tactics' failure for backtracking and
repetition.
As an example of the former, the tactic $t_1 \;\mathsf{Orelse}\; t_2$,
constructed using the $\mathsf{Orelse}$ tactical, executes $t_1$ and if it
fails, then $t_2$.
As an example of the latter, consider the tactic $\mathsf{Repeat}\; t$.
It executes the tactic $t$:
on failure, nothing happens;
on success, $\mathsf{Repeat}\; t$ is executed on every subgoal generated by the
successful application of $t$.

A strength of the LCF system is that users may define their own tactics, but
this comes also at a cost.
Users must also therefore define the validation associated to their tactic.
Granting totally unrestricted power to the user in constructing theorems would
be a huge blow to any potential soundness guarantee for the system.
Instead, only limited power is given to the user, as Milner says that
``the only operations for generating [theorems] are the basic
inference rules ... and the rules derived from them.''
But this isn't quite enough either.
Nothing (statically) prevents a user from defining what Milner calls an
``invalid'' tactic.
%
He writes in \cite{lcf},
\begin{quote}
  Validity is clearly a necessary condition for a tactic to be useful; indeed we
  may deny that invalid tactics are tactics at all.  But it is hard to see how
  to design a programming language so that all definable objects of type
  \texttt{tactic} are valid, or how to gain this effect by a type discipline.
  At most we can adopt a style which encourages the programming of valid
  tactics; this can be done with tacticals.
\end{quote}
%
Milner shows on paper that given valid tactics, his predefined tacticals
generate valid tactics. But to reiterate, the overall soundness of the system is
undermined by the user's ability to define and use invalid tactics and
tacticals.

\subsection{Tactics in Isabelle}

\newcommand{\isb}{Isabelle-88}

In the early 80's, Lawrence Paulson assists Milner in the development of the
LCF system in Edinburgh. Once Paulson's time in Scotland ends, he travels
south to England, taking with him the insights from the LCF system to create
Cambridge LCF, which goes on to become the Isabelle-86 and later the \isb{}
system \cite{isabelle-origin}.

Both \isb{} and Edinburgh LCF use ML as a form of interactivity with the
user.
That is, theorems can be proven interactively purely via the ML
read-eval-print loop (REPL).
The main downside to this approach is that anything is possible:
this REPL allows general-purpose programming in ML, of which one potential
application is the development of proofs.
In other words, \isb{} is an ML library rather than an application per se.
The functions representing tactics must be applied manually to
values representing goals to build new goal values.
These entities must all be managed directly by the user.

To alleviate some of this manual labour, a helper library called the
\emph{goal stack package} is bundled together with \isb{} that automates much of
the goal management.
It provides a notion of a current goal state, an undo mechanism, and a helper
for invoking a tactic on the current state.
This helper adds any new goals generated by the tactic to the goal stack.

\isb{} builds substantially on Edinburgh LCF.
First, whereas LCF is specialized for reasoning about a particular logic called
\textsc{pplambda}, \isb{} aims to be a \emph{generic} theorem prover, capable of
reasoning about several logics that one would encode in it\footnotemark.
Second, as for the tactic languages, one key development in \isb{} is the
removal of validations, those functions used to construct a forwards proof
once the tactic-based backwards proof is complete.
%
\footnotetext{%
  A similar drive to represent represent and reason about a broader class of
  logics also takes place in Edinburgh, culminating with the development of the
  Edinburgh logical framework LF~\cite{Harper93jacm}.%
}
%
Recall that these validations are a source of concern in Edinburgh LCF as users
can define invalid tactics, whose validations construct a proof for the the
wrong theorem.
A shift in the representation technique for inference rules is what enables
explicit, manual validations to be eliminated.
Rather than represent inference rules as opaque functions, they are represented
directly as data in the system.
From this representation, both forwards reasoning functions as in LCF and
backwards reasoning tactics can be derived.
Moreover, the application of a tactic automatically derived from an inference
rule performs the work of LCF's validations behind the scenes as what Paulson
calls a ``meta-inference''.
Since a new object-logic is encoded by extending \isb's meta-logic
\newcommand{\M}{$\mathcal{M}$}%
\M{} with additional axioms representing as
(meta-)implications the inference rules of the object-logic,
reasoning in the metalanguage \M{} amounts to reasoning in the object-logic.
In fact, an entire intermediate \emph{proof state} for a theorem in an object
language is represented as a \emph{theorem} in \M.
Hence, it is by checking inferences \emph{in \M{}} that the system ensures that
every proof state is arrived at correctly.
Users may define new tactics, but these, by virtue of ultimately using the
primitive tactics representing inference rules, effectively represent
\emph{derived} inference rules in the object language.

Although the underlying details of tactics are quite different, the tactics and
tacticals themselves are mostly the same, and remain quite powerful.
Tacticals for repetition, backtracking, and so on are all present in
\isb.
Paulson demonstrates the power of tacticals by using them to build a proof
search strategy for classical first-order logic.
Paulson's strategy is to divide inference rules into two categories
that he calls ``safe'' and ``unsafe''.
A rule that can be applied eagerly, without affecting the provability of the
overall statement, is safe; else it is unsafe.
Then, one applies as many safe rules as possible until applying one unsafe rule,
and repeating.
% This technique would later be further developed by Andreoli, in the setting of
% linear logic, where it is called ``focusing'' and where the categories of rules
% are called ``asynchronous'' and ``synchronous'' \cite{andreoli-logic-1992}.
% That Paulson be able to implement such a powerful proof search technique using
% only a handful of combinators speaks to the strength of tacticals.

Now it seems that there are two different views of tactics.
Some tactics represent (derived) inference rules in the object-logic, whereas
others represent proof search and automation techniques.
It is not immediately clear that these two views can be reconciled.
Inference rules have clear conditions under which they may apply, and their
outcomes are predictable, whereas proof search techniques have less clear
applicability conditions and their outcomes can be uncertain.
These two different views were already present in LCF, and we will see that
these two views appear in later systems, too.

% \inlinetodo{%
%   Discuss that the tactic language is low-level. Subgoals are referred to by
%   number.
% }
%
% \inlinetodo{%
%   Discuss that tactics in isabelle emit not only a \emph{list} of subgoals,
%   but a potentially infinite stream of subgoals.
%   Also, it's super unclear how that works at all: does one need only solve
%   \emph{one} of these subgoals? Or all of them?  Or is the stream purely for
%   nondeterminism in the proof search?
% }

\section{Languages for defining tactics}
\label{sec:defining-tactics}

\isb{} and LCF do not have proper languages for defining tactics.
Instead, one defines tactics essentially by extending the proof assistant
itself.
This works reasonably well in those settings because the assistant is
interpreted, and we can think of the assistant not as an application itself, but
rather as a library implemented in ML.
The upshot is that one can use the ML REPL to develop proofs interactively.

When a proof assistant is its own, separate application, then the development of
new tactics cannot reasonably proceed by extending the assistant itself.
Therefore, we see a drive to design languages for defining the new tactics.

\subsection{Tactic languages for Coq}

In the mid-80s, as LCF and Isabelle are developed in Scotland and England,
Thierry Coquand and Gérard Huet develop the Calculus of Constructions in France
\cite{coc}.
This is a higher-order constructive logic possessing all forms of quantification
(in the sense of Barendregt's lambda cube \cite{barendregt-lambda}).
Furthermore, they developed an implementation of this logic, called
Coq\footnotemark.
What distinguishes Coq from LCF and Isabelle is that it is designed with
\emph{program extraction} in mind.
This technique recovers from a proof object its computational component as an
executable program in a conventional programming language, e.g. ML.
%
% \inlinetodo{%
%   Discuss the addition of inductive families in the Calculus of Inductive
%   Constructions?
% }

\footnotetext{%
  The system was itself called \textsc{CoC} and then \textsc{constr} for several
  years before being renamed, but I will refer to it only as Coq for simplicity.
}

As a highly simplified but concrete example, consider a $\Pi_1$ formula, of the
form $\forall x{:}\tau_1.\exists y{:}\tau_2.P$.
In constructive logic, existential claims actually contain an object that
witnesses the claimed existence.
Then it seems possible to transform this logical statement into a program that,
given an $x{:}\tau_1$, computes the $y{:}\tau_2$ that witnesses the claim.
That is, one can recover an ordinary function of type $\tau_1 \to \tau_2$.
% \inlinetodo{Say something about Curry-Howard and erasure of computationally
%   irrelevant parts of the proof term?}

This extraction process enables the development of \emph{verified algorithms}.
First, one uses the system to prove a theorem, e.g. ``for any list $l$, there
exists a list $l^\prime$ such that $l^\prime$ contains exactly the elements of
$l$ and such that $l^\prime$'s elements are in ascending order''.
Then, one uses program extraction to obtain from this theorem a proper sorting
algorithm together with a guarantee of this algorithm's correctness.

Similar to LCF and Isabelle, Coq features a number of tactics and tacticals to
aid in proof development.
The original tactics are much like LCF's and Isabelle's, so I will not describe
them.
An important difference, however, between Coq and the other systems I have
described, is that Coq is a proper application written in ML\footnotemark,
with its own syntax, parser, etc.
%
\footnotetext{%
  Coq has been implemented in many different ML languages over the years, first
  in CAML, then in Caml-light, and finally (and still to this day) in OCaml.
  To simplify, I will say that Coq is merely implemented in ML.
}
%
In other words, users do not interact with Coq via the ML REPL.
This has two unfortunate downsides for the extensibility of Coq's tactic
language.
First, it is challenging to add new tactics to Coq, as one must obtain the
source code for Coq, implement the new tactics in ML, and recompile the system
as a whole.
Second, the distribution of custom tactics is difficult: should one ask that
one's domain-specific tactic be included in the core system, or should one
circulate a patch file to be applied to the system's source tree?
Neither of these distribution strategies is particularly satisfying.
Domain specific tactics should probably not be included in the core distribution
of the system, else users eventually find themselves drowning in an abundance of
highly specialized tactics unnecessary to their specific problem domain.
The circulation of patches, on the other hand, requires that one keep their
patches constantly up to date with the current distributed version of the
system.

At last, a solution appears at the turn of the millenium as David Delahaye
announces the Ltac language \cite{Delahaye:LPAR00}.
Ltac is a domain-specific language embedded within Coq for defining new
tactics.
Essentially, scripts in Ltac are interpreted to execute commands in Coq's
kernel.
The benefits of Ltac are that it is high-level compared to implementing tactics
directly in ML and that new tactics can be defined alongside proofs.
In fact, Delahaye reports significant code size reductions (and even sometimes
speedups!) in tactics ported from ML to Ltac.
Since custom tactics can be defined together with one's proofs, tactic and even
proof distribution are vastly simplified.
Indeed, Pierre Pédrot later writes in \cite{ltac2}, ``the Ltac tactic language
is probably one of the major ingredients of the success of [Coq], as it allows
to write proofs in an incremental, more efficient and more robust way that the
state of the art at that time.''

To illustrate one particularly high-level construct from Ltac called
\texttt{match goal}, let us consider an example from Delahaye's paper, in which
he proves that the natural numbers have more than two elements.
This statement can be expressed formally as
\newcommand{\N}{\mathbb{N}}%
\[
  \neg (\exists x{:}\N.\exists y{:}\N.\forall z{:}\N.\, x = z \lor y = z)
\]
%
% \footnotetext{%
%   In the version of Ltac presented by Delahaye, the construct is called
%   \texttt{Match Context}, and overall his example no longer works with the
%   latest version of Coq.
%   I will discuss an updated version of the example that I have produced.
%   See Appendix~\ref{app:delahaye-example-contrast} for the original and updated
%   versions of the example.
% }
%
The proof stategy is to assume the negated formula and arrive at a
contradiction.
The assumed existential claim can be decomposed, assuming the existence of such
an $x$ and such a $y$.
Then, it suffices to instantiate the assumption $\forall z{:}\N. x = z \lor y =
z$ with three distinct numbers, say $1$, $2$, and $3$.
At this point, we have three relevant assumptions:
\renewcommand{\H}{\mathcal{H}}
$\H_1 :: x = 1 \lor y = 1$,
$\H_2 :: x = 2 \lor y = 2$, and
$\H_3 :: x = 3 \lor y = 3$.
Successively eliminating these assumptions can be accomplished quite easily with
the \texttt{;} (semicolon) tactical, which applies the tactic on the right to
each subgoal generated by the tactic on the left:
\newcommand{\elim}{\mathtt{elim}\;}
$\elim \H_1;\; \elim \H_2;\; \elim \H_3$.
In detail, the first elimination generates two subgoals, and \emph{for each} of
these, the second elimination generates two subgoals,
\emph{and for each of those}, the third elimination generates two subgoals.
This exponential blowup results in eight subgoals, each of which contains a
pair of assumptions of the form $x = a$ and $x = b$, or $y = a$ and $y = b$ for
distinct constants $a$, $b$.

Ltac's \texttt{match goal} construct is a form of pattern matching for
extracting parts of the active subgoal.
One can match on available assumptions as well as on the current goal.
The pattern Delahaye uses is \texttt{[_ : ?x = ?a, H : ?x = ?b |- _]}.
The turnstile separates the hypothesis pattern from the goal pattern.
The question mark syntax expresses metavariables, and the nonlinear appearance
of \texttt{?x} will involve unification during matching.
This pattern can match all eight of the subgoals that we have generated, as
each of them contain (at least) the assumptions of the written forms.
Then, in the body of this branch, we eliminate the first equality using
\texttt{subst x}, refining the type of \texttt{H} to evidently be uninhabited,
as it states an equality between two syntactically unequal, closed terms.
Then we eliminate the absurd assumption \texttt{H} using the
\texttt{discriminate} tactic to produce the required contradiction.
Since we want to perform this general analysis on all eight subgoals, we
sequentially compose the \texttt{match goal} construct with the eliminations
using \texttt{;}.
See Fig.~\ref{fig:ltac-example} for the full example.

\begin{figure}[t]
  \lstinputlisting[language=Coq]{snippets/nat-card.v}%
  \caption{%
    A simple theorem on the cardinality of natural numbers, to illustrate the
    \texttt{match goal} construct in Ltac.%
  }
  \label{fig:ltac-example}
\end{figure}

The beauty of Ltac is that this basic recipe could be further generalized to
prove that the natural numbers have more than $n$ elements for a closed $n$.
First eliminate the $n$ nested existentials. Second, eliminate the universal
$n + 1$ times, with distinct naturals, e.g. $0$ through $n$.
Finally, end the proof in the same way, using \texttt{match goal} to find a pair
of equalities that can be used to produce a contradiction.

The main downside to Ltac is that it is ill-specified.
Indeed, Delahaye does not give any semantics for tactics defined in
Ltac, and upon Ltac's release, it was not typed.
The lack of a typing discipline would not, however, be a dealbreaker, given that
Ltac runs during typechecking anyway:
any runtime error during execution of an Ltac script becomes a
type error at its invocation site.
Overall, the lack of specification is acceptable at the time of Ltac's release
as the language eliminates a growing problem with custom tactics by allowing
users to define simple custom tactics while encouraging them to implement
larger, more sophisticated ones in ML.

Alas, it is all too common for domain-specific languages to outgrow their
original scope, and Ltac is no exception.
Over the following two decades, several other approaches to programming
tactics in Coq are proposed:
Mtac~\cite{mtac-journal} / Mtac2~\cite{mtac2}, Rtac~\cite{rtac},
Template-Coq~\cite{template-coq} / MetaCoq~\cite{metacoq}, and
Ltac2~\cite{ltac2} to name a few.
I briefly discuss each of these lines of work.

\subsubsection{Mtac / Mtac2}

\newcommand{\trun}{{\bfseries run}}
\newcommand{\mtac}{\bigcirc}
The Mtac project broadly aims to give a static type system to tactics,
encapsulating the effects that tactics wish to use inside a monad.
Mtac extends Coq with a monadic type family $\mtac$ for forming a type $\mtac
\tau$ that expresses that if the tactic terminates successfully, then it generates
a Coq term of type $\tau$.
The constructors for this type family include the usual monadic operations,
together with many useful combinators for tactic programming, e.g. fixed points,
exception handling, pattern matching, and more.
The primitive tactic execution construct \texttt{\trun{} t} has type
$\tau$ assuming that $t$ has type $\mtac \tau$.
This construct is eliminated during type inference.
If type inference succeeds without generating any exceptions, then all instances
of \texttt{\trun} have been replaced with ordinary Coq terms.
Consequently, the trusted Coq kernel does not need to be extended to handle
\texttt{\trun}.
Like in Ltac, an Mtac program is ``untrusted'' in the sense that it must be
executed to generate a term and that term must be typechecked.
The downside to this is that very large proof terms could be generated by
seemingly simple tactics (as a result of proof search), which negatively impacts
the performance of typechecking.

\inlinetodo{Say something about how Mtac2 builds on Mtac1?}

\subsubsection{Rtac}

The Rtac project~\cite{rtac} of Gregory Malecha et al.
seeks to address performance issues with Ltac
and
belongs to a family of approaches called \emph{reflective metaprogramming}.
Such an approach provides primitives for quoting and unquoting terms from the
proof assistant itself: a Coq term is \emph{reified} (quoted) into a value of a
concrete Coq datatype, transformed according to the implementation of the
tactic, and then \emph{reflected} (unquoted) back.

Rtac distinguishes itself from other reflective metaprogramming techniques
(e.g. in Agda~\cite{agda-reflection} or in Template-Coq) by allowing the user to
define a custom concrete syntax that is the target of reification.
Hence, a tactic needs only to consider the cases for that syntax instead of the
syntax for the entire assistant.

Rtac's main motivation is not ease-of-use or safety, but actually
\emph{performance}.
To use an example from~\cite{rtac}, consider the problem of checking equality in
a commutative monoid, e.g. checking that $x \oplus 2 \oplus 3 \oplus 4 = 4
\oplus 3 \oplus 2 \oplus x$.
One could write an Ltac program prove this directly, using transitivity of
equality to witness a series of permutations of elements on the left until they
match those on the right.
Such an Ltac program is not particularly hard to write, but the generated proof
following this strategy is generally quadratic in the size of the input.
A more clever proof would flatten these expressions into lists and
check that one is a permutation of the other.
Malecha describes this technique in detail in~\cite{rtac} using Rtac, and the
resulting proof is linear in the input size.
On large enough input sizes (8 elements in the commutative monoid equivalence
example), these improved asymptotics outweigh the cost of reification and
reflection.

Alas, there are some additional requirements to make this approach work:
the user must prove a soundness lemma for their tactic.
This lemma expresses that if the tactic decides that the two reified terms
are syntactically equal, then their reflections are also equal.
Malecha addresses this concern by providing a number of tacticals such that
tactics built using them can have their soundness lemmas automatically
derived.
However, more sophisticated tactics that cannot be built out of the provided
tacticals will require soundness lemmas to be proven manually.
Further limitations of the Rtac system is that its internal language is
simply-typed, so Rtac cannot reify dependently-typed terms.

\subsubsection{Template-Coq / MetaCoq}

The recent MetaCoq~\cite{metacoq} project is quite large, having several goals.
Among them are reification and reflection of terms as well as a monadic
interpreter for scripting tactics.
(Its goals less relevant to us, but nonetheless quite impressive, include a full
specification of Coq's typing and operational semantics as well as a correctness
proof of a functional typechecker for Coq.)
MetaCoq essentially merges the Mtac2 and Template-Coq projects:
it keeps Mtac's idea of using a monad to capture effects that tactics need
(such as nontermination, backtracking, state, etc.) but it replaces Mtac's
shallow embedding of Coq terms with Template-Coq's deep embedding.

\newcommand{\tmonad}{\texttt{TemplateMonad}}
In more detail, MetaCoq's \tmonad{} is defined as a free monad in Coq.
This is essentially a syntactic device that happens to be a monad, but must
later be interpreted to have any effect.
The interpretation is defined in OCaml as a Coq plugin.
The free monad definition includes functions for quoting various constructs in
Coq, such as terms, inductive types, universes, and constants.

The concrete syntax into which terms are reified is a simple type \texttt{term}
and nothing prevents a MetaCoq program from manipulating these in ways that
violate scoping, let alone typing.
This is in fact intended by the authors, as the alternative (as developed in
Agda~\cite{agda-reflection}) is to use sophisticated
concepts such as inductive-recursive (IR) and quotient inductive-inductive types
(QIITs) to obtain an intrinsically-typed representation of the syntax.
Significant extensions to Coq's metatheory would be required to accommodate IR
and QIITs.

Given that MetaCoq's concrete representation of terms is untyped, there are two
forms of unquoting available: \texttt{tmUnquote t} and \texttt{tmUnquoteTyped A t}.
Both of these infer some type for the unquoted term. In the former, the inferred
type is existentially quantified, so there is no way to know the
type\footnote{Since pattern matching on types is forbidden}.
In the latter, one specifies an expected type \texttt{A} to
\texttt{tmUnquoteTyped} and the system requires that the inferred type for
\texttt{t} unify with \texttt{A}.
Recall that all of these operations take place within \tmonad, so any type
inference failure (or unification failure in \texttt{tmUnquoteTyped}) will cause
an exception in the monad.

Although Ltac and Mtac programs can generate only terms, Template-Coq and by
extension MetaCoq are capable of generating full toplevel definitions, as in
Template Haskell~\cite{template-haskell}.
This makes it possible to do such things as defining new inductive types and
to generically generate lemmas by inspecting the shapes of inductive types.
The authors do not discuss at length how one defines new tactics using MetaCoq,
since this is not their primary aim. They claim, however, that MetaCoq can act
as a foundation for eventually building domain-specific tactic languages in the
style of Ltac and Mtac.

\subsubsection{Ltac2}

All competitors to Ltac surveyed so far offer a brand new approach entirely,
namely by using an explicit monad or reflection (or both in the case of MetaCoq).
For a traditional Ltac user, it can be challenging to adopt these techniques
since they differ quite a lot from Ltac.
The Ltac2 project~\cite{ltac2} addresses this by explicitly aiming to resemble
Ltac, maintaining a strong degree of backwards compatibility.

Although it resembles Ltac on the surface, Ltac2 is a proper ML language.
It is ``call-by-value and effectful, supports algebraic datatypes and allows
prenex polymorphism''.
The ability to define datatypes in Ltac2 is a huge improvement, as it allows
writing tactics that use data structures such as lists and dictionaries.
Like Ltac, Ltac2 uses runtime checks to ensure that generated terms are
well-typed.

Ltac2 features a macro system of ``notations'' together with a metaprogramming
system of quotations and antiquotations for Coq terms.
This is similar to the notation system in Ltac, so it should be familiar to
users.
The key difference is that each notation is associated with a \emph{scope},
which is a function that expands syntax on the fly.
The notion of scope is made higher-order by introducing
\emph{scope combinators}.
For example, the \texttt{ident} scope for parsing identifiers can easily be made
into a scope for parsing a list of identifiers using the \texttt{list0} scope
transformer.
This leverages the existence of data structures, generating a \emph{list} of
identifiers.

% Overall, Ltac2 represents an improvement over Ltac all the while remaining
% similar to it.
% Rather than start from scratch in designing a good tactic language from the
% ground up, the Ltac2 developers started from Ltac and built on it.

\subsection{VeriML}

\newcommand{\lhol}{$\lambda \mathsf{HOL}_{ind}$}
Although the Coq ecosystem sees a lot of development regarding tactic languages,
some have thought to distance themselves from the Calculus of Constructions to
bring new insights.
VeriML~\cite{Stampoulis:ICFP10, Stampoulis:POPL12} is an ML-like language for
developing proof automation.  It is very expressive, having references and
general recursion.

A key idea in this system is to clearly separate the logical language
\lhol{} from the computation language: propositions and proofs are explicitly
embedded into the computation language using an angle-bracket syntax $\langle
\cdot \rangle$.
VeriML features a form of dependent types in which objects representing proofs
are indexed by the proposition they prove.
Furthermore, following~\cite{Nanevski:ICML05,Pientka:PPDP08}, logical terms come
packaged with the context in which they are meaningful.
Abstraction over contexts is also possible, to express that a function can work
in any context.

The language \lhol{} is a higher-order logic augmented with inductive types and
the ability to define total recursive functions.
It can be seen as a common core between the Calculus of Inductive
Constructions%
\footnote{%
  This is the Calculus of Constructions augmented with inductive
  families~\cite{dybjer-inductive}. %
}~\cite{cic} (CIC) and systems in the HOL family such as Isabelle.
Rather than use a pattern matching construct, which is quite complex in the
presence of dependent types (see \cite{goguen-eliminating-2006}), \lhol{} uses
eliminators.
That is, when one defines a new inductive type, the system synthesizes a special
constant called an \emph{eliminator} for that type. This is essentially a
function from the newly defined type into some other type family of one's
choosing%
\footnote{%
  To use Conor McBride's terminology, this family is called the \emph{motive} of
  the elimination~\cite{mcbride-elimination-2002}.%
}.
To use the eliminator, one must also provide a number of \emph{methods}: given
that an inductive type is a sum of products, each method handles one branch of
the sum. Recursive occurrences of the inductive type within a branch become
replaced by the motive. From a proof-theoretic point of view, these replacements
correspond to available induction hypotheses.

The benefit of using eliminators over the more familiar pattern matching and
explicit recursion is that eliminators greatly simplify totality checking.
In fact, the type of the eliminator itself is constructed so that totality is
guaranteed.
The downside to eliminators is that the selection of a motive can be quite
tricky, making programming using eliminators quite challenging.
\inlinetodo{An example? e.g. zero not the succ of any nat?}

The computation language of VeriML manipulates contextual \lhol{} terms.
These terms are \lhol{} terms together with a context in which they are
meaningful:
a contextual term $[\phi] t$ may mention in $t$ free variables that are listed
in the context $\phi$.
Although \lhol{} uses eliminators to define total functions, the computation
language of VeriML uses the usual pattern matching and explicit recursion of
functional programming.
The need to use eliminators to simplify totality checking is unnecessary in the
computation language as this language admits and embraces nontermination.
The construct $\mathtt{holcase}\;T\;\mathtt{of}\cdots$ is used to perform
dependent pattern matching on the contextual \lhol{} term $T$.
Given that this matching is dependent, the branches may have different types,
according to the refinement generated by matching the term $T$ against the
pattern of the branch.

The expressivity of VeriML makes it possible to define sophisticated decision
procedures and proof automation without worrying about termination and by using
powerful imperative data structures.
In~\cite{Stampoulis:ICFP10}, the author uses these features to implement for
example a decision procedure for the theory of equality with uninterpreted
functions (EUF).
This theory is generated by the usual axioms of equality
(reflexivity, symmetry, and transitivity) together with the rule
$x = y \implies f\, x = f\, y$.
The functions $f$ are uninterpreted in the sense that they do not have any
associated reduction behaviour, unlike e.g. in the theory of arithmetic where
the function $+$ has such a behaviour.
A problem in EUF asks whether a given equation is true in a context of assumed
equations.
The standard technique for deciding this theory is to use a union-find data
structure to find equivalence classes of terms according to the assumed
equations.
Then it suffices to check whether the two terms of interest belong to the same
equivalence class.
Although persistent implementations of the union-find data structure have been
developed (see~\cite{union-find}), the traditional implementation is
imperative.
The imperative features of VeriML make it easy to port this implementation
straight from standard algorithms textbooks.

\section{Structured editing}
\label{sec:structured-editing}

Although Harpoon uses a tactic language for interfacing with the user, these
tactics are not really of primary interest, since they are not
recorded.
Instead, applying a tactic elaborates a (partial)
\emph{structured proof script}, which is recorded to a file.
Therefore, we can see Harpoon as a high-level editor for proof scripts.
An editor aware of the structure of the document being edited is called a
\emph{structured editor}%
\footnote{%
  Other names include \emph{structural editor}, \emph{syntax-directed editor},
  and \emph{projectional editor}.%
}.

Usually, editing source code means writing text which is then parsed according
to the grammar of the language being written.
Nothing prevents writing text that is unmeaningful: one can easily write in
Emacs some text that does not parse.
In a structured editor, edit actions are restricted so they respect the grammar
of the language, making it impossible to construct syntactically incorrect
programs.
These editors have a notion of ``hole'', which stands for a node in the abstract
syntax tree (AST) that remains to be constructed by the user.

Perhaps the biggest success of structured editors today is in teaching
programming to children: the Scratch language~\cite{scratch}, designed to be
user-friendly and using a GUI for editing, is a syntactic structure editor.
The benefit in an educational setting is that learners can focus immediately on
computational thinking, bypassing any struggle with program syntax.

Another advantage of structured editors is that they can more easily provide
editing services such as syntax highlighting, type-aware code completion, and
automated refactoring.
These operations require that the program being analyzed or transformed be
syntactically or semantically meaningful, so traditional editors must
selectively disable them or employ ad hoc heuristics when a malformed program is
encountered.
This is a nonissue in a structured editor, which needs not even concern itself
with malformed program text.

However, some editing services do require not only syntactically meaningful
programs, but also semantically meaningful programs.
The Hazelnut system~\cite{hazelnut} gives a theoretical foundation for a
structured editor in which every edit state is semantically meaningful.
That is, every edit state is well-typed.

The challenge in this development is to preserve some degree of
user-friendliness: naively enforcing typing would require the user to construct
programs in a very rigid, outside-in form.
For instance, the user would have to identify that they wish to construct a
function \emph{application} before they identify the function they wish to call.
Even worse, in a functional language encouraging currying, due to
left-associativity, the programmer would have to construct the appropriate
\emph{number} of application nodes before specifying the function to call!

The solution to this is one of Hazelnut's key innovations:
a hole in a program may be \emph{nonempty}.
In this case, the hole is understood not as a mere missing AST node, but as an
internalized type mismatch.
The content of the hole must internally be well-typed, but crucially it can have
\emph{any} type.

For example, consider a hole of type $B$. We wish to fill it with a function
application $f\;a$ for some $f : A \to B$ and $a : A$.
We first construct a reference to the function $f$.
This is ill-typed: the expected type is $B$ but the inferred type of $f$ is $A
\to B$.
Thus the variable $f$ is placed \emph{inside} the hole, witnessing the type
mismatch.
Then, inside the hole we construct the application node, placing the variable
$f$ as the left child and specify the argument $a$ as the right child.
The type of the expression inside the hole is now $B$, matching the expected
type outside the hole, so the hole vanishes, becoming replaced by its contents.

\newcommand{\hole}[1]{\llparenthesis #1 \rrparenthesis}
To properly separate the notions of inferred and expected type, Hazelnut is
presented as a bidirectional type system.
Both empty holes $\hole{}$ and nonempty holes $\hole{e}$ are classified as
synthesizable expressions.
A nonempty hole's body $e$ must synthesize some type $\tau$, so the hole must be
internally well-typed, but both an empty and a nonempty hole synthesize the hole
type $\hole{}$.
Note that although \emph{expression holes} may be nonempty, \emph{type holes}
are always empty.

In a traditional bidirectional type system, the rule for switching from the
checking mode to the synthesis mode has the additional premise that the
synthesized type be convertible (or made convertible via unification) with the
type being checked against.
In Hazelnut, the notion of type equality used in this situation is called
\emph{type consistency}, and crucially it accounts for the hole type $\hole{}$
being ``equal'' to any other type.
As for checking against the hole type, additional consideration is necessary.
Consider the situation $\Gamma \proves \lambda x.\; e \chk \hole{}$.
The hole type $\hole{}$ expands into $\hole{} \to \hole{}$ so that the
context is extended with the declaration $x{:}\hole{}$ and the body of the
lambda is further checked against $\hole{}$.
Extending the system with additional type formers (e.g. product types or sum
types) requires corresponding new judgments to handle such hole type expansions.

Hazelnut's metatheory is rich and interesting: not only are the traditional
progress and preservation theorems proven, but also the authors show several
results concerning the interactive nature of their system, which they call a
\emph{structured editor calculus}.
Recall that Hazelnut has a notion of cursor that is superimposed onto
expressions.
The programmer manipulates the cursor and constructs AST nodes using interactive
commands called \emph{actions}.
Here is a summary of the main results concerning actions.
All this metatheory is mechanized in Agda.
\begin{itemize}
\item The program is invariant under movement actions, i.e. movement actions
  affect only the cursor.
\item From any cursor position, a sequence of movement actions exists
  to bring the cursor to any other position.
\item For any well-typed expression, there exists a sequence of actions to
  construct it interactively.
\end{itemize}

Hazelnut's edit actions bear a resemblance to tactics.
A key difference is that in tactic-based systems, the cursor is less explicit and
can be focused only on a subgoal, whereas in Hazelnut the cursor can be moved
around anywhere in the expression.
Hazelnut's edit actions include also a command for deleting a node, replacing it
with a subgoal.
This is more general than a mere undo mechanism as it appears in tactic-based
systems.

The notion of nonempty holes in Hazelnut gives a uniform way to handle backwards
reasoning. This distinguishes Hazelnut from traditional tactic-based systems,
which employ special tactics for backwards reasoning.
However, any backwards reasoning performed in a nonempty hole is obscured in the
final expression: by merely seeing a function application, for example, one
cannot know whether it was constructed in a forwards or backwards style.

\section{Beluga}
\label{sec:beluga-intro}

Harpoon is an interactive frontend for Beluga~\cite{Cave:POPL12}.
One develops a proof interactively using Harpoon, and this proof can either
remain as a proof script, or it can be translated into a Beluga program.
It is this translation that justifies our claim that a Harpoon proof script
truly does represent a proof.
Considering this, it is essential to first describe Beluga.
The main technical exposition of Beluga is given in Sec.~\ref{sec:beluga}
before we describe Harpoon's metatheory, so this section will focus Beluga's
proof-theoretic background and on a high-level overview.

\subsection{Contextual Modal Type Theory}

Beluga is based on Contextual Modal Type Theory~\cite{Nanevski:ICML05}.
Although Beluga is dependently-typed, I will discuss the simply-typed Contextual
Modal Type Theory here.
This theory can be obtained from simple type theory by internalizing the notion
of \emph{context}.
First, the syntax of types is extended to include the form $[\Psi]A$, called a
\emph{boxed type}.
A term of this type represents a hypothetical derivation depending on the
context $\Psi$ and concluding $A$.
Second, the typing judgment $\Delta; \Gamma \proves t : A$ mentions two
contexts:
$\Gamma$ contains ordinary assumptions whereas $\Delta$ contains contextual
assumptions.
A contextual assumption has the form $u : A[\Psi]$ in which the
contextual variable $u$ expresses that $A$ is true in the context $\Psi$.
Contextual variables are also called \emph{metavariables}.
One must take care to distinguish an ordinary assumption of a boxed type
$x : [\Psi]A$ from a contextual assumption $u : A[\Psi]$.
The introduction and elimination rules for boxed types are the following.
\[
  \infer{%
    \Delta; \Gamma \proves \mathsf{box}(\Psi.\; M) : [\Psi]A
  }{%
    \Delta; \Psi \proves M : A
  }
  \quad
  \infer{%
    \Delta; \Gamma \proves \mathsf{letbox}(M, u.\; N) : C
  }{%
    \Delta; \Gamma \proves M : [\Psi]A
    &
    \Delta, u{:}A[\Psi]; \Gamma \proves N : C
  }
\]
In the introduction rule, $M$ is a hypothetical derivation concluding $A$ and
depending on the assumptions $\Psi$.
In the elimination rule, we wish to prove $C$ using the hypothetical derivation
$M$ depending on $\Psi$. The context $\Delta$ becomes extended with a new
contextual variable, and we conduct the proof $N$ of $C$ in this extended
context.
In other words, rather than demand upfront that the assumptions $\Psi$ be
instantiated with some terms, this is delayed until the moment that the
contextual variable is used. To use a contextual variable, one provides an
explicit substitution that maps the context of that assumption into the current
context.
\[
  \infer{%
    \Delta, u{:}A[\Psi]; \Gamma \proves \mathsf{clo}(u, \sigma) : A
  }{%
    \Delta, u{:}A[\Psi]; \Gamma \proves \sigma : \Psi
  }
\]

Now let us see how these ideas scale up to dependent types and are applied in
Beluga.
Beluga is a two-layer system:
the language one writes inside a box differs from the language one writes
outside the box.
Inside the box, one uses LF~\cite{Harper93jacm} to uniformly represent the
syntax and the derivations of an encoded language.
(We discuss concretely in Chap.~\ref{chap:example} how to encode a language in
Beluga, using the simply-typed lambda calculus as an example.)

\inlinetodo{I AM HERE}


Beluga is a dependently-typed functional programming language.
Following the Curry-Howard correspondence, a proof is represented as a total
function understood as mapping the premises of a theorem to its conclusion.
Beluga's form of dependent types differs from that in languages such as Coq or
Agda.
One can quantify over any type in those systems, whereas in Beluga one
quantifies only over a specific index domain.
In general, this index domain can be natural numbers, strings, or
lists~\cite{ChH03Pha, Xi:POPL03}, but Beluga fixes the domain to be (contextual)
LF objects and first-class contexts and substitutions over these objects.
LF is well-suited for encoding languages with binders, using higher-order
abstract systax (HOAS)~\cite{something-for-hoas}.
Not only does the indexed type system help simplify Beluga's metatheory, but it
also enforces a separation between the language's encoding and its metatheory.






%
%%% Local Variables:
%%% TeX-master: "../main.tex"
%%% End:
